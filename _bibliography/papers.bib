---
---

@misc{xia2024letsthinkvarbyvarlarge,
      abbr={ARXIV 2024},
      title={Let's Think Var-by-Var: Large Language Models Enable Ad Hoc Probabilistic Reasoning}, 
      author={Shepard Xia and Brian Lu and Jason Eisner},
      year={2024},
      eprint={2412.02081},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      bibtex_show = {true},
      pdf={https://arxiv.org/abs/2412.02081}, 
      abstract="A hallmark of intelligence is the ability to flesh out underspecified situations using ``common sense.'' We propose to extract that common sense from large language models (LLMs), in a form that can feed into probabilistic inference. We focus our investigation on guesstimation questions such as ``How much are Airbnb listings in Newark, NJ?'' Formulating a sensible answer without access to data requires drawing on, and integrating, bits of common knowledge about how Price andLocation may relate to other variables, such as Property Type. Our framework answers such a question by synthesizing an ad hoc probabilistic model. First we prompt an LLM to propose a set of random variables relevant to the question, followed by moment constraints on their joint distribution. We then optimize the joint distribution p within a log-linear family to maximize the overall constraint satisfaction. Our experiments show that LLMs can successfully be prompted to propose reasonable variables, and while the proposed numerical constraints can be noisy, jointly optimizing for their satisfaction reconciles them. When evaluated on probabilistic questions derived from three real-world tabular datasets, we find that our framework performs comparably to a direct prompting baseline in terms of total variation distance from the dataset distribution, and is similarly robust to noise."
}

@inproceedings{chi-et-al-2023,
  abbr={INTERSPEECH 2023},
  author =      {Jie Chi* and Brian Lu* and Jason Eisner and Peter Bell
                 and Preethi Jyothi and Ahmed M. Ali},
  title =       {Unsupervised Code-Switched Text Generation from
                 Parallel Text},
  booktitle =   {Proceedings of INTERSPEECH},
  year =        {2023},
  month =       aug,
  address =     {Dublin},
  bibtex_show = {true},
  pdf =         {http://cs.jhu.edu/~jason/papers/#chi-et-al-2023},
  abstract = "There has been great interest in developing automatic speech recognition (ASR) systems that can handle code-switched (CS) speech to meet the needs of a growing bilingual population. However, existing datasets are limited in size. It is expensive and difficult to collect real transcribed spoken CS data due to the challenges of finding and identifying CS data in the wild. As a result, many attempts have been made to generate synthetic CS data. Existing methods either require the existence of CS data during training, or are driven by linguistic knowledge. We introduce a novel approach of forcing a multilingual MT system that was trained on non-CS data to generate CS translations. Comparing against two prior methods, we show that simply leveraging the shared representations of two languages (Mandarin and English) yields better CS text generation and, ultimately, better CS ASR."
}

@inproceedings{lu-etal-2019-look,
    abbr={EMNLP 2019},
    title = "Look-up and Adapt: A One-shot Semantic Parser",
    author = "Lu*, Zhichu  and
      *Arabshahi, Forough  and
      Labutov, Igor  and
      Mitchell, Tom",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    bibtex_show = {true},
    pdf = "https://aclanthology.org/D19-1104/",
    pages = "1129--1139",
    abstract= "Computing devices have recently become capable of interacting with their end users via natural language. However, they can only operate within a limited ``supported'' domain of discourse and fail drastically when faced with an out-of-domain utterance, mainly due to the limitations of their semantic parser. In this paper, we propose a semantic parser that generalizes to out-of-domain examples by learning a general strategy for parsing an unseen utterance through adapting the logical forms of seen utterances, instead of learning to generate a logical form from scratch. Our parser maintains a memory consisting of a representative subset of the seen utterances paired with their logical forms. Given an unseen utterance, our parser works by looking up a similar utterance from the memory and adapting its logical form until it fits the unseen utterance. Moreover, we present a data generation strategy for constructing utterance-logical form pairs from different domains. Our results show an improvement of up to 68.8{\%} on one-shot parsing under two different evaluation settings compared to the baselines."
}

@misc{arabshahi2020compositionalgeneralizationtreestack,
    abbr={ARXIV 2020},
      title={Compositional Generalization with Tree Stack Memory Units}, 
      author={Forough Arabshahi* and Zhichu Lu* and Pranay Mundra and Sameer Singh and Animashree Anandkumar},
      year={2020},
      eprint={1911.01545},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      bibtex_show = {true},
      pdf={https://arxiv.org/abs/1911.01545}, 
      abstract="We study compositional generalization, viz., the problem of zero-shot generalization to novel compositions of concepts in a domain. Standard neural networks fail to a large extent on compositional learning. We propose Tree Stack Memory Units (Tree-SMU) to enable strong compositional generalization. Tree-SMU is a recursive neural network with Stack Memory Units (\SMU s), a novel memory augmented neural network whose memory has a differentiable stack structure. Each SMU in the tree architecture learns to read from its stack and to write to it by combining the stacks and states of its children through gating. The stack helps capture long-range dependencies in the problem domain, thereby enabling compositional generalization. Additionally, the stack also preserves the ordering of each node's descendants, thereby retaining locality on the tree. We demonstrate strong empirical results on two mathematical reasoning benchmarks. We use four compositionality tests to assess the generalization performance of Tree-SMU and show that it enables accurate compositional generalization compared to strong baselines such as Transformers and Tree-LSTMs."
}
